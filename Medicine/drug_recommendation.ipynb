{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ffb986d",
   "metadata": {},
   "source": [
    "# Medicine Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d86fc162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "# a list of most common words in English\n",
    "stop_words = [\n",
    "    'a', 'about', 'after', 'all', 'also', 'an', 'and', 'any', 'as', 'at',\n",
    "    'be', 'because', 'but', 'by', 'can', 'come', 'could', 'day', 'do', 'does', 'did', 'done',\n",
    "    'dont', 'even', 'find', 'first', 'for', 'from', 'get', 'give', 'go', 'have', 'has', 'had',\n",
    "    'he', 'her', 'here', 'him', 'his', 'how', 'i', 'ive', 'im', 'if', 'in', 'into',\n",
    "    'it', 'its', 'just', 'know', 'like', 'look', 'make', 'man', 'many',\n",
    "    'me', 'more', 'my', 'new', 'no', 'not', 'now', 'of', 'on', 'one',\n",
    "    'only', 'or', 'other', 'our', 'out', 'people', 'say', 'see', 'she',\n",
    "    'so', 'some', 'take', 'tell', 'than', 'that', 'the', 'their', 'them',\n",
    "    'then', 'there', 'these', 'they', 'thing', 'think', 'this', 'those',\n",
    "    'time', 'to', 'two', 'up', 'use', 'very', 'want', 'was', 'way', 'we', 'well',\n",
    "    'what', 'when', 'which', 'who', 'will', 'with', 'would', 'year', 'you',\n",
    "    'your'\n",
    "]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9fe5d",
   "metadata": {},
   "source": [
    "## Load & Preprocess the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14375e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the train data = 161297\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9</td>\n",
       "      <td>20-May-12</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>27-Apr-10</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>14-Dec-09</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8</td>\n",
       "      <td>3-Nov-15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9</td>\n",
       "      <td>27-Nov-16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID                  drugName                     condition  \\\n",
       "0    206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1     95260                Guanfacine                          ADHD   \n",
       "2     92703                    Lybrel                 Birth Control   \n",
       "3    138000                Ortho Evra                 Birth Control   \n",
       "4     35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"It has no side effect, I take it in combinati...       9  20-May-12   \n",
       "1  \"My son is halfway through his fourth week of ...       8  27-Apr-10   \n",
       "2  \"I used to take another oral contraceptive, wh...       5  14-Dec-09   \n",
       "3  \"This is my first time using any form of birth...       8   3-Nov-15   \n",
       "4  \"Suboxone has completely turned my life around...       9  27-Nov-16   \n",
       "\n",
       "   usefulCount  \n",
       "0           27  \n",
       "1          192  \n",
       "2           17  \n",
       "3           10  \n",
       "4           37  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"drugsComTrain_raw.csv\")\n",
    "print(\"Number of entries in the train data = %d\"%(len(train_df)))\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "287a3a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries in the test data = 53766\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueID</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>163740</td>\n",
       "      <td>Mirtazapine</td>\n",
       "      <td>Depression</td>\n",
       "      <td>\"I&amp;#039;ve tried a few antidepressants over th...</td>\n",
       "      <td>10</td>\n",
       "      <td>28-Feb-12</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206473</td>\n",
       "      <td>Mesalamine</td>\n",
       "      <td>Crohn's Disease, Maintenance</td>\n",
       "      <td>\"My son has Crohn&amp;#039;s disease and has done ...</td>\n",
       "      <td>8</td>\n",
       "      <td>17-May-09</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>159672</td>\n",
       "      <td>Bactrim</td>\n",
       "      <td>Urinary Tract Infection</td>\n",
       "      <td>\"Quick reduction of symptoms\"</td>\n",
       "      <td>9</td>\n",
       "      <td>29-Sep-17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39293</td>\n",
       "      <td>Contrave</td>\n",
       "      <td>Weight Loss</td>\n",
       "      <td>\"Contrave combines drugs that were used for al...</td>\n",
       "      <td>9</td>\n",
       "      <td>5-Mar-17</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97768</td>\n",
       "      <td>Cyclafem 1 / 35</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I have been on this birth control for one cyc...</td>\n",
       "      <td>9</td>\n",
       "      <td>22-Oct-15</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniqueID         drugName                     condition  \\\n",
       "0    163740      Mirtazapine                    Depression   \n",
       "1    206473       Mesalamine  Crohn's Disease, Maintenance   \n",
       "2    159672          Bactrim       Urinary Tract Infection   \n",
       "3     39293         Contrave                   Weight Loss   \n",
       "4     97768  Cyclafem 1 / 35                 Birth Control   \n",
       "\n",
       "                                              review  rating       date  \\\n",
       "0  \"I&#039;ve tried a few antidepressants over th...      10  28-Feb-12   \n",
       "1  \"My son has Crohn&#039;s disease and has done ...       8  17-May-09   \n",
       "2                      \"Quick reduction of symptoms\"       9  29-Sep-17   \n",
       "3  \"Contrave combines drugs that were used for al...       9   5-Mar-17   \n",
       "4  \"I have been on this birth control for one cyc...       9  22-Oct-15   \n",
       "\n",
       "   usefulCount  \n",
       "0           22  \n",
       "1           17  \n",
       "2            3  \n",
       "3           35  \n",
       "4            4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"drugsComTest_raw.csv\")\n",
    "print(\"Number of entries in the test data = %d\"%(len(test_df)))\n",
    "test_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ea30c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of conditions in the train data = 885\n",
      "Number of conditions in the test data = 709\n",
      "32 test conditions are not found in the train data\n"
     ]
    }
   ],
   "source": [
    "# unique set of conditions\n",
    "conditions_train = set(train_df['condition'])\n",
    "print(\"Number of conditions in the train data = %d\"%(len(conditions_train)))\n",
    "\n",
    "conditions_test = set(test_df['condition'])\n",
    "print(\"Number of conditions in the test data = %d\"%(len(conditions_test)))\n",
    "\n",
    "# test conditions which are not in the train set\n",
    "print(\"%d test conditions are not found in the train data\" %len(conditions_test - conditions_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c264724b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drugs in the train data = 3436\n",
      "Number of drugs in the test data = 2637\n",
      "235 test drugs are not found in the train data\n"
     ]
    }
   ],
   "source": [
    "# unique set of drugs\n",
    "drugs_train = set(train_df['drugName'])\n",
    "print(\"Number of drugs in the train data = %d\"%(len(drugs_train)))\n",
    "\n",
    "drugs_test = set(test_df['drugName'])\n",
    "print(\"Number of drugs in the test data = %d\"%(len(drugs_test)))\n",
    "\n",
    "# test drugs which are not in the train set\n",
    "print(\"%d test drugs are not found in the train data\" %len(drugs_test - drugs_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fb863",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "The `drugName` column has sometimes multiple drugs mentioned in the same column (e.g. Acetaminophen / chlorpheniramine / dextromethorphan / pseudoephedrine). Split them on '/'. But it can introduce unwanted splitting (e.g. Cyclafem 7 / 7 / 7 is a single drug Cyclafem 7-7-7). Convert all drug names to lowercase to avoid any duplicates.\n",
    "\n",
    "#### Clean Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f2be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map drugs to symptoms:\n",
    "# Use two separate lists for that.\n",
    "train_symptoms = []\n",
    "train_drugs = []\n",
    "\n",
    "for idx, row in train_df.iterrows():\n",
    "    # convert review text to lower case\n",
    "    review = row['review'].lower().replace(\"&#039;\", \"'\") \\\n",
    "                                        .replace(\"&amp;\", ' ') \\\n",
    "                                        .replace(\"&quot;\", ' ')\n",
    "    \n",
    "    # remove punctuations & digits\n",
    "    review = re.sub(r'[^A-Za-z ]+', '', review)\n",
    "        \n",
    "    # remove stopwords (common english words such as \"the\")\n",
    "    filtered_tokens = [word for word in review.split() if word not in stop_words]\n",
    "    review = ' '.join(filtered_tokens)\n",
    "    \n",
    "    # add the condition to the symptoms for better review\n",
    "    condition = row['condition']\n",
    "    if not pd.isna(condition) and \"comment\" not in condition:\n",
    "        # convert to lowercase\n",
    "        condition = condition.lower()\n",
    "        # keep only alphabets\n",
    "        condition = re.sub(r'[^A-Za-z ]+', '', condition)\n",
    "    \n",
    "        # add to the review\n",
    "        review = condition + \" \" + review\n",
    "\n",
    "    # process drug names\n",
    "    drugName = row['drugName']\n",
    "    # Replace \"/\" with \"-\" when surrounded by a number or a single alphabet\n",
    "    drugName = re.sub(r'(\\b\\d|[A-Za-z])\\s*\\/\\s*(\\d|\\b[A-Za-z])\\b', r'\\1-\\2', drugName)\n",
    "    \n",
    "    # if multiple drugs in the same line separated by \"/\"\n",
    "    for drug in drugName.split('/'):\n",
    "        train_drugs.append(drug.strip().lower())\n",
    "        train_symptoms.append(review)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f885ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183239"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_drugs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a59d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiv infection jan th diagnosed hiv cd vl didnt stribild til may nd taking months reached cd vl und medicaid without supplement plan pay everything pay copay'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_symptoms[10000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1915c7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75160\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer on the train symptoms to learn the vocabulary\n",
    "vectorizer.fit(train_symptoms)\n",
    "\n",
    "# Get the vocabulary\n",
    "vocabulary = vectorizer.vocabulary_\n",
    "\n",
    "print(len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea0bc0",
   "metadata": {},
   "source": [
    "#### Clean Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7524b713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map drugs to symptoms:\n",
    "# Use two separate lists for that.\n",
    "test_symptoms = []\n",
    "test_drugs = []\n",
    "\n",
    "for idx, row in test_df.iterrows():\n",
    "    # convert review text to lower case\n",
    "    review = row['review'].lower().replace(\"&#039;\", \"'\") \\\n",
    "                                        .replace(\"&amp;\", ' ') \\\n",
    "                                        .replace(\"&quot;\", ' ')\n",
    "    \n",
    "    # remove punctuations & digits\n",
    "    review = re.sub(r'[^A-Za-z ]+', '', review)\n",
    "        \n",
    "    # remove stopwords (common english words such as \"the\")\n",
    "    filtered_tokens = [word for word in review.split() if word not in stop_words]\n",
    "    review = ' '.join(filtered_tokens)\n",
    "    \n",
    "    # add the condition to the symptoms for better review\n",
    "    condition = row['condition']\n",
    "    if not pd.isna(condition) and \"comment\" not in condition:\n",
    "        # convert to lowercase\n",
    "        condition = condition.lower()\n",
    "        # keep only alphabets\n",
    "        condition = re.sub(r'[^A-Za-z ]+', '', condition)\n",
    "    \n",
    "        # add to the review\n",
    "        review = condition + \" \" + review\n",
    "\n",
    "    # process drug names\n",
    "    drugName = row['drugName']\n",
    "    # Replace \"/\" with \"-\" when surrounded by a number or a single alphabet\n",
    "    drugName = re.sub(r'(\\b\\d|[A-Za-z])\\s*\\/\\s*(\\d|\\b[A-Za-z])\\b', r'\\1-\\2', drugName)\n",
    "    \n",
    "    # if multiple drugs in the same line separated by \"/\"\n",
    "    # if multiple drugs in the same line separated by \"/\"\n",
    "    for drug in drugName.split('/'):\n",
    "        test_drugs.append(drug.strip().lower())\n",
    "        test_symptoms.append(review)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20fe4dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61004"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_drugs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5eee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of drugs in the train data = 3264\n",
      "Number of drugs in the test data = 2520\n",
      "216 test drugs are not found in the train data\n"
     ]
    }
   ],
   "source": [
    "# re-calculate unique set of drugs\n",
    "drugs_train = set(train_drugs)\n",
    "print(\"Number of drugs in the train data = %d\"%(len(drugs_train)))\n",
    "\n",
    "drugs_test = set(test_drugs)\n",
    "print(\"Number of drugs in the test data = %d\"%(len(drugs_test)))\n",
    "\n",
    "# test drugs which are not in the train set\n",
    "print(\"%d test drugs are not found in the train data\" %len(drugs_test - drugs_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c59d1f6",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Use Bag of Words approach using CountVectorizer to convert the symptoms text to a vector. \n",
    "\n",
    "Use one-hot encoding of the target (drugs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b43ac6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Create an instance of OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Fit and transform the unique drugs to one-hot vectors\n",
    "encoder.fit([[drug] for drug in drugs_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6dfe4430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3264"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = [x.replace('x0_', '') for x in encoder.get_feature_names_out()]\n",
    "len(feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a7166b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_names.pkl']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the feature_names list\n",
    "joblib.dump(feature_names, 'feature_names.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51a36e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183239, 3264)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode training data labels\n",
    "train_drugs_one_hot = encoder.transform([[drug] for drug in train_drugs])\n",
    "train_drugs_one_hot.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7012c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize the training data & test data\n",
    "train_data = vectorizer.transform(train_symptoms)\n",
    "test_data = vectorizer.transform(test_symptoms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c4e9670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183239, 75160)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7daf595",
   "metadata": {},
   "source": [
    "## Build PyTorch Model\n",
    "We use a feed forward neural network having two hidden layers with 100 neurons each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fa52ccf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95344f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 100]       7,516,100\n",
      "           Dropout-2                  [-1, 100]               0\n",
      "            Linear-3                  [-1, 100]          10,100\n",
      "           Dropout-4                  [-1, 100]               0\n",
      "            Linear-5                 [-1, 3264]         329,664\n",
      "================================================================\n",
      "Total params: 7,855,864\n",
      "Trainable params: 7,855,864\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.29\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 29.97\n",
      "Estimated Total Size (MB): 30.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Define the dimensions\n",
    "input_dim = train_data.shape[1] # 75160\n",
    "hidden_dim = 100\n",
    "output_dim = train_drugs_one_hot.shape[1] # 3264\n",
    "\n",
    "# Define the neural network architecture\n",
    "class FeedForwardNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedForwardNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.dropout2 = nn.Dropout(0.25)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(torch.relu(self.fc1(x)))\n",
    "        x = self.dropout2(torch.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        # x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "# Create the model instance\n",
    "model = FeedForwardNN(input_dim, hidden_dim, output_dim)\n",
    "summary(model, (input_dim,))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bce96e",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c9fa13a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset to convert data batch by batch\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return train_drugs_one_hot.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Convert the sparse matrix batch to dense tensor\n",
    "        data_batch = self.data[index].toarray()  \n",
    "        target_batch = self.targets[index].toarray()\n",
    "        return torch.FloatTensor(data_batch), target_batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ec0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the batch size\n",
    "batch_size = 128\n",
    "\n",
    "# Create a custom dataset for training\n",
    "train_dataset = CustomDataset(train_data, train_drugs_one_hot)\n",
    "\n",
    "# Create a DataLoader for batch training\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create the model instance\n",
    "model = FeedForwardNN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8feb6135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Batch [500/1432], Average Loss: 0.03452077120685376\n",
      "Epoch [1/10], Batch [1000/1432], Average Loss: 0.0025105766070095225\n",
      "Epoch [2/10], Batch [500/1432], Average Loss: 0.0021160443795910757\n",
      "Epoch [2/10], Batch [1000/1432], Average Loss: 0.001953746064210692\n",
      "Epoch [3/10], Batch [500/1432], Average Loss: 0.0017230466032329302\n",
      "Epoch [3/10], Batch [1000/1432], Average Loss: 0.0016369445565395698\n",
      "Epoch [4/10], Batch [500/1432], Average Loss: 0.0015036201657990004\n",
      "Epoch [4/10], Batch [1000/1432], Average Loss: 0.0014557190611460217\n",
      "Epoch [5/10], Batch [500/1432], Average Loss: 0.0013382527247505695\n",
      "Epoch [5/10], Batch [1000/1432], Average Loss: 0.0013027985708612085\n",
      "Epoch [6/10], Batch [500/1432], Average Loss: 0.0012007186437623968\n",
      "Epoch [6/10], Batch [1000/1432], Average Loss: 0.0011803605684078938\n",
      "Epoch [7/10], Batch [500/1432], Average Loss: 0.0010918484713543285\n",
      "Epoch [7/10], Batch [1000/1432], Average Loss: 0.0010816638625268534\n",
      "Epoch [8/10], Batch [500/1432], Average Loss: 0.0010059597765249718\n",
      "Epoch [8/10], Batch [1000/1432], Average Loss: 0.001007727915000681\n",
      "Epoch [9/10], Batch [500/1432], Average Loss: 0.0009446646868415628\n",
      "Epoch [9/10], Batch [1000/1432], Average Loss: 0.0009462846073552445\n",
      "Epoch [10/10], Batch [500/1432], Average Loss: 0.0008949355750130927\n",
      "Epoch [10/10], Batch [1000/1432], Average Loss: 0.0009004524830803836\n"
     ]
    }
   ],
   "source": [
    "# Run training for 10 epochs\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for i, (inputs, targets) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Print training loss occasionally\n",
    "        if (i + 1) % 500 == 0:  # Print every 500 batches\n",
    "            avg_loss = total_loss / 500\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{i+1}/{len(train_dataloader)}], Average Loss: {avg_loss}\")\n",
    "            total_loss = 0.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8b100467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained model\n",
    "torch.save(model.state_dict(), 'model.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee7564",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "844d26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, test_sample, n=3):\n",
    "    '''\n",
    "    Return top-n predictions of the test_sample\n",
    "    '''\n",
    "    # model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # convert test sample to torch tensor\n",
    "    test_sample = test_sample.toarray()\n",
    "    test_tensor = torch.FloatTensor(test_sample)\n",
    "    \n",
    "    # make prediction\n",
    "    output = model(test_tensor)\n",
    "    softmax = F.softmax(output, dim=1)[0]\n",
    "    \n",
    "    # Get the top n values and their indices\n",
    "    top_values, top_indices = torch.topk(softmax, k=n)\n",
    "    \n",
    "    top_n_idx = top_indices[:n]\n",
    "    \n",
    "    result = []\n",
    "    for idx in top_n_idx:\n",
    "        result.append(feature_names[idx])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a01de955",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mirtazapine', 'amitriptyline', 'remeron']"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_prediction(model, test_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba9c28",
   "metadata": {},
   "source": [
    "## Check Accuracy\n",
    "We perform a top-n accuracy check on the train & test datasets.\n",
    "\n",
    "The model will make n (typically n=3) predictions. If the actual drug given matches any of this n drugs, we call that as a success. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b05a2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check train accuracy\n",
    "correct = 0\n",
    "for sample, label in zip(train_data, train_drugs):\n",
    "    # get the top-n outputs\n",
    "    preds = make_prediction(model, sample, n=3)\n",
    "\n",
    "    if label in preds:\n",
    "        correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9b172e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy = 84.556%\n"
     ]
    }
   ],
   "source": [
    "train_acc = correct/train_data.shape[0]\n",
    "print(\"Train Accuracy = %.3f%%\"%(train_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a547a21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 74.405%\n"
     ]
    }
   ],
   "source": [
    "# check test accuracy\n",
    "correct = 0\n",
    "for sample, label in zip(test_data, test_drugs):\n",
    "    # get the top-n outputs\n",
    "    preds = make_prediction(model, sample, n=3)\n",
    "\n",
    "    if label in preds:\n",
    "        correct += 1\n",
    "        \n",
    "test_acc = correct/test_data.shape[0]\n",
    "print(\"Test Accuracy = %.3f%%\"%(test_acc*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7d15d8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer.pkl']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the CountVectorizer object\n",
    "joblib.dump(vectorizer, 'vectorizer.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79904239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Usage: streamlit run [OPTIONS] TARGET [ARGS]...\n",
      "\n",
      "Error: Invalid value: File does not exist: filename.py\n"
     ]
    }
   ],
   "source": [
    "!streamlit run filename.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe557f90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
